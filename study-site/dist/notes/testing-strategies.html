<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="description" content="Senior .NET study guide for Testing Strategies" />
  <title>Testing Strategies | C# Interview Prep Cheat Sheet</title>
  <link rel="stylesheet" href="../assets/styles.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
</head>
<body>
  <header class="site-header">
    <div>
      <p class="eyebrow">C# Interview Prep</p>
      <h1>Senior .NET Study Portal</h1>
      <p class="subtitle">Ultimate cheat sheets, patterns, and interview-ready scenarios in one place.</p>
    </div>
    <div class="badge">Fast recall</div>
  </header>
  <div class="layout">
    <nav class="sidebar">
      <div class="sidebar-section">
        <h2>Navigation</h2>
        <div class="search-hint">Use Ctrl/Cmd + F for quick lookup</div>
        <div class="nav-groups"><div class="sidebar-group">
      <h3>Notes</h3>
      <ul><li><a href="../notes/sub-notes/Async Await Deep Dive.html">Async Await Deep Dive</a></li><li><a href="../notes/Automapper/AutoMapper.html">AutoMapper</a></li><li><a href="../notes/sub-notes/base-keyword.html">Base Keyword</a></li><li><a href="../notes/sub-notes/CLR & Garbage Collector (GC).html">CLR & Garbage Collector (GC)</a></li><li><a href="../notes/sub-notes/CLR & Garbage Collector (GC) Practical Example.html">CLR & Garbage Collector (GC) Practical Example</a></li><li><a href="../notes/core-concepts.html">Core Concepts</a></li><li><a href="../notes/Design-Patterns/CQRS Pattern.html">CQRS Pattern</a></li><li><a href="../notes/SOLID/D-Dependency-Inversion-Principle-DIP.html">D Dependency Inversion Principle DIP</a></li><li><a href="../notes/Design-Patterns/Decorator Pattern.html">Decorator Pattern</a></li><li><a href="../notes/sub-notes/Dependency Injection Lifetimes.html">Dependency Injection Lifetimes</a></li><li><a href="../notes/error-handling.html">Error Handling</a></li><li><a href="../notes/Design-Patterns/Factory Pattern.html">Factory Pattern</a></li><li><a href="../notes/sub-notes/FIFO Queues in .NET.html">FIFO Queues In .NET</a></li><li><a href="../notes/FluentValidation/FluentValidation.html">FluentValidation</a></li><li><a href="../notes/sub-notes/Forcing Garbage Collection.html">Forcing Garbage Collection</a></li><li><a href="../notes/SOLID/I-Interface-Segregation-Principle-ISP.html">I Interface Segregation Principle ISP</a></li><li><a href="../notes/sub-notes/IDisposable Patterns.html">IDisposable Patterns</a></li><li><a href="../notes/Clean-Architecture/index.html">Index</a></li><li><a href="../notes/DRY/index.html">Index</a></li><li><a href="../notes/Memory-Allocation-Discipline/index.html">Index</a></li><li><a href="../notes/SOLID/index.html">Index</a></li><li><a href="../notes/SOLID/L-Liskov-Substitution-Principle-LSP.html">L Liskov Substitution Principle LSP</a></li><li><a href="../notes/logging.html">Logging</a></li><li><a href="../notes/Design-Patterns/Mediator Pattern.html">Mediator Pattern</a></li><li><a href="../notes/Memory-Allocation-Discipline/Memory Allocation Discipline Example.html">Memory Allocation Discipline Example</a></li><li><a href="../notes/Memory-Allocation-Discipline/Memory Allocation Discipline Example Async.html">Memory Allocation Discipline Example Async</a></li><li><a href="../notes/sub-notes/nameof-keyword.html">Nameof Keyword</a></li><li><a href="../notes/sub-notes/NET Generational Garbage Collection (GC) Deep Dive.html">NET Generational Garbage Collection (GC) Deep Dive</a></li><li><a href="../notes/SOLID/O-Open-Closed-Principle-OCP.html">O Open Closed Principle OCP</a></li><li><a href="../notes/Design-Patterns/Observer Pattern.html">Observer Pattern</a></li><li><a href="../notes/sub-notes/RabbitMQ.html">RabbitMQ</a></li><li><a href="../notes/sub-notes/Reflection Overview.html">Reflection Overview</a></li><li><a href="../notes/SOLID/S-Single-Responsibility-Principle-SRP.html">S Single Responsibility Principle SRP</a></li><li><a href="../notes/sub-notes/Server vs Workstation GC.html">Server Vs Workstation GC</a></li><li><a href="../notes/sub-notes/Sorted Collections Interview Notes.html">Sorted Collections Interview Notes</a></li><li><a href="../notes/sub-notes/Sorting Algorithms.html">Sorting Algorithms</a></li><li><a href="../notes/Design-Patterns/Strategy Pattern.html">Strategy Pattern</a></li><li><a href="../notes/sub-notes/struct vs class when to use which.html">Struct Vs Class When To Use Which</a></li><li><a href="../notes/testing-strategies.html">Testing Strategies</a></li><li><a href="../notes/sub-notes/types.html">Types</a></li></ul>
    </div><div class="sidebar-group">
      <h3>Practice</h3>
      <ul><li><a href="../practice/answers.html">Answers</a></li><li><a href="../practice/csharp-system-design-questions.html">Csharp System Design Questions</a></li><li><a href="../practice/questions.html">Questions</a></li><li><a href="../practice/real exam questions answers/replace int without variable.html">Replace Int Without Variable</a></li><li><a href="../practice/real exam questions answers/struct vs class questions and answers.html">Struct Vs Class Questions And Answers</a></li></ul>
    </div></div>
      </div>
    </nav>
    <main class="content">
      <article class="card">
        <div class="breadcrumbs">notes/testing-strategies.md</div>
        <h2>Testing Strategies</h2>
        <div class="toc-label">Rapid overview</div>
        <div class="toc"><ul class="toc-list"><li class="level-1"><a href="#testing-strategies-for-high-performance-highly-available-systems">Testing Strategies for High-Performance, Highly Available Systems</a></li><li class="level-2"><a href="#unit-tests">Unit Tests</a></li><li class="level-2"><a href="#integration-tests">Integration Tests</a></li><li class="level-2"><a href="#cross-cutting-testing-practices">Cross-Cutting Testing Practices</a></li><li class="level-2"><a href="#when-discussing-in-an-interview">When Discussing in an Interview</a></li><li class="level-2"><a href="#questions-answers">Questions & Answers</a></li></ul></div>
        <h1 id="testing-strategies-for-high-performance-highly-available-systems">Testing Strategies for High-Performance, Highly Available Systems</h1>
<p>Use these notes to articulate how you design and execute tests that protect performance, availability, and correctness. Keep them alongside the core concepts cheat sheet and tailor examples to your services.</p>
<p>---</p>
<h2 id="unit-tests">Unit Tests</h2>
<p>```csharp public class BalanceServiceTests { private readonly Mock<IAccountStore> _store = new(); private readonly BalanceService _sut;</p>
<ul><li><strong>Purpose:</strong> Validate a single class/function in isolation with deterministic inputs/outputs.</li><li><strong>Isolation:</strong></li><li>Mock external dependencies (I/O, network, time) with interfaces and test doubles.</li><li>Use in-memory fakes for lightweight state (e.g., <code>InMemoryRepository</code>) but prefer mocks for behavior verification.</li><li><strong>Patterns:</strong></li><li><strong>Arrange-Act-Assert (AAA):</strong> Make the phases explicit; minimize setup repetition with builders/AutoFixture.</li><li><strong>Given-When-Then naming:</strong> <code>GivenHealthyAccount_WhenWithdraw_ThenBalanceUpdated</code> for intent clarity.</li><li><strong>Table-driven tests:</strong> Iterate over scenarios via <code>Theory</code>/<code>InlineData</code> in xUnit to keep cases compact.</li><li><strong>xUnit + Moq + Shouldly example:</strong></li></ul>
<p>public BalanceServiceTests() { _sut = new BalanceService(_store.Object); }</p>
<p>[Theory] [InlineData(100, 40, 60)] [InlineData(50, 25, 25)] public async Task GivenBalance_WhenWithdraw_ThenBalanceUpdated(decimal starting, decimal debit, decimal expected) { // Arrange _store.Setup(s => s.GetAsync("id", It.IsAny<CancellationToken>())) .ReturnsAsync(new Account("id", starting));</p>
<p>// Act await _sut.WithdrawAsync("id", debit, CancellationToken.None);</p>
<p>// Assert _store.Verify(s => s.SaveAsync(It.Is<Account>(a => a.Balance == expected), It.IsAny<CancellationToken>())); _sut.LastLatencyMs.ShouldBeLessThan(5); // Cheap guardrail for perf-sensitive code paths } } ```</p>
<ul><li><strong>Performance-aware design:</strong></li><li>Avoid sleeping; use <code>TestScheduler</code>/<code>ManualResetEventSlim</code> for timing-sensitive logic.</li><li>Keep allocations predictable—reuse fixture data/builders instead of newing objects per assertion.</li><li>Target micro-benchmarks separately with BenchmarkDotNet rather than overloading unit tests.</li><li><strong>Reliability:</strong></li><li>No hidden global state; reset static caches/singletons between runs.</li><li>Keep unit tests idempotent and order-independent.</li></ul>
<h2 id="integration-tests">Integration Tests</h2>
<p>```csharp public class HealthEndpointTests : IClassFixture<WebApplicationFactory<Program>> { private readonly HttpClient _client;</p>
<ul><li><strong>Purpose:</strong> Validate real wiring: DI container, middleware, persistence, messaging, and observability hooks.</li><li><strong>Environment strategy:</strong></li><li>Run against ephemeral infra (Testcontainers/Docker Compose) with realistic versions of databases/queues.</li><li>Seed data via migrations + fixtures; tear down cleanly to avoid cross-test coupling.</li><li>Use unique resource names (DB names, queues) per test run to enable parallel execution.</li><li><strong>Patterns:</strong></li><li><strong><code>WebApplicationFactory</code>/<code>MinimalApiFactory</code>:</strong> Spin up APIs in-memory with production middleware, swapping only endpoints you must stub (e.g., external HTTP clients).</li><li><strong>Contract tests:</strong> Validate message schemas and HTTP contracts against consumer/provider expectations.</li><li><strong>Idempotency checks:</strong> Re-run the same operation twice and assert consistent results to mirror at-least-once delivery.</li><li><strong>Minimal integration test example (xUnit + WebApplicationFactory + Shouldly):</strong></li></ul>
<p>public HealthEndpointTests(WebApplicationFactory<Program> factory) { _client = factory.CreateClient(new WebApplicationFactoryClientOptions { AllowAutoRedirect = false }); }</p>
<p>[Fact] public async Task GetHealth_ReturnsOkAndBudgetedLatency() { var stopwatch = ValueStopwatch.StartNew(); var response = await _client.GetAsync("/health"); var elapsedMs = stopwatch.GetElapsedTime().TotalMilliseconds;</p>
<p>response.StatusCode.ShouldBe(HttpStatusCode.OK); elapsedMs.ShouldBeLessThan(50, "health endpoints must stay fast to avoid liveness probe churn"); } } ```</p>
<ul><li><strong>Performance & HA focus:</strong></li><li>Assert on latency budgets (e.g., middleware response times) with histogram/percentile metrics exposed in tests.</li><li>Simulate failure modes: kill containers, drop network, poison queue messages, exhaust connection pools—verify graceful degradation and recovery.</li><li>Validate circuit breakers, bulkheads, and timeouts are configured with realistic thresholds.</li></ul>
<h2 id="cross-cutting-testing-practices">Cross-Cutting Testing Practices</h2>
<ul><li><strong>Test data discipline:</strong> Centralize builders/fixtures to avoid duplication and to make hot-path payloads realistic (size, shape, field optionality).</li><li><strong>Observability hooks:</strong> Assert logs/metrics/traces for key scenarios (success, validation errors, retries). Use in-memory exporters for OpenTelemetry.</li><li><strong>Deterministic time & randomness:</strong> Inject clocks/<code>Random</code> seeds; freeze time in tests to avoid flakiness.</li><li><strong>Parallelism:</strong> Mark tests <code>Collection</code>-safe; isolate shared resources to allow high-concurrency runs in CI without interference.</li><li><strong>CI pipeline:</strong></li><li>Run unit tests fast on every push; gate integration/system tests on main merge or nightly.</li><li>Capture artifacts (logs, coverage, traces) to speed triage when failures occur.</li><li><strong>Coverage mindset:</strong> Optimize for risk: critical paths (auth, payments, risk controls), failure handling, and regression-prone areas get deeper coverage.</li></ul>
<h2 id="when-discussing-in-an-interview">When Discussing in an Interview</h2>
<ul><li><strong>Narrative:</strong> Outline pyramid strategy—fast unit tests, targeted integration, and a few end-to-end paths covering the golden user journeys.</li><li><strong>Performance posture:</strong> Emphasize how tests enforce latency/error budgets and protect against resource exhaustion (threads, sockets, DB connections).</li><li><strong>Availability posture:</strong> Highlight chaos/failover scenarios you automate (leader election, connection drop, retry storms) and how you keep tests isolated and repeatable.</li><li><strong>Tooling:</strong> Mention xUnit, AutoFixture/FluentAssertions for clarity; Testcontainers/Docker Compose for realistic environments; Polly + OpenTelemetry assertions for resilience.</li></ul>
<p>---</p>
<p>Keep these patterns close to the code you ship—optimize for speed, determinism, and confidence without slowing delivery.</p>
<p>---</p>
<h2 id="questions-answers">Questions & Answers</h2>
<p><strong>Q: How do you prevent performance regressions from slipping through unit tests?</strong></p>
<p>A: Keep micro-benchmarks in BenchmarkDotNet projects, but add lightweight latency guards to hot-path unit tests (e.g., <code>ShouldBeLessThan</code> on critical methods) and fail builds on meaningful percentile shifts in CI metrics exports. Use deterministic data builders to avoid noisy allocations that mask regressions.</p>
<p><strong>Q: What is your approach to testing high-availability scenarios in integration tests?</strong></p>
<p>A: Exercise failure modes intentionally: kill containers, drop network connections, or poison queue messages using Testcontainers hooks. Assert that retries, circuit breakers, and bulkheads recover within error budgets, and verify observability signals (logs/metrics/traces) show the expected degradation and recovery steps.</p>
<p><strong>Q: How do you keep integration tests parallelizable without flakiness?</strong></p>
<p>A: Use unique resource identifiers (database names, queue topics, blob prefixes) per test run, isolate shared state through fixtures, and ensure teardown cleans resources. Mark collection fixtures to avoid serial bottlenecks and rely on containerized dependencies to avoid cross-test interference.</p>
<p><strong>Q: When is it appropriate to include chaos testing in CI?</strong></p>
<p>A: Run minimal chaos probes (like restarting a dependency once) on main-branch merges to catch regressions early, but reserve heavier scenarios (multi-node failovers, prolonged network partitions) for nightly or pre-release pipelines to balance feedback speed with stability.</p>
<p><strong>Q: How do you validate observability instrumentation through tests?</strong></p>
<p>A: Attach in-memory exporters for OpenTelemetry during integration tests, trigger key user journeys, and assert on emitted spans/metrics/logs (names, attributes, and error flags). This ensures dashboards and alerts stay trustworthy without requiring external telemetry backends.</p>
      </article>
    </main>
  </div>
  <footer class="footer">Built for disciplined study & interview drills.</footer>
</body>
</html>